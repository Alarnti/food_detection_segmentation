{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781571ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import typing\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from collections import defaultdict, deque\n",
    "import datetime\n",
    "import pickle\n",
    "import time\n",
    "import torch.distributed as dist\n",
    "import errno\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchmetrics.detection.map import MeanAveragePrecision\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.dataset import FoodDataset\n",
    "from src.vis import read_image, show_image_coco\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00571cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "TRAIN_IMAGES_PATH = 'data/public_training_set_release_2.0/images/'\n",
    "TRAIN_LABELS = 'data/public_training_set_release_2.0/annotations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4fc615",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = COCO(TRAIN_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c7e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30708b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = labels.getImgIds()\n",
    "#184135\n",
    "labels.imgToAnns[img_ids[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels.getCatIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52115149",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_coco(img_ids[1], TRAIN_IMAGES_PATH, labels, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7481cac8",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40972650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.cpu().eval()\n",
    "labels.loadImgs(img_ids[0])\n",
    "\n",
    "raw_val = [train_ds[i] for i in range(0,10)]\n",
    "trgt = [raw_val[i][1] for i in range(0,10)]\n",
    "im_val = [torch.mul(255, raw_val[i][0]) for i in range(0,10)]\n",
    "# im_val1 = [torch.from_numpy(im_val).float()]\n",
    "res = model_ft(im_val)\n",
    "pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metr = MeanAveragePrecision(\n",
    "                box_format='xyxy',\n",
    "                iou_thresholds=None,\n",
    "                rec_thresholds=[1, 10, 100],\n",
    "                class_metrics=False,\n",
    "                )\n",
    "\n",
    "metr.update(res, trgt)\n",
    "pprint(metr.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd272a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask rcnn model\n",
    "num_classes = 498\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model_ft = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model_ft.roi_heads.box_predictor.cls_score.in_features\n",
    "model_ft.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "in_features_mask = model_ft.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "hidden_layer = 256\n",
    "model_ft.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "model_ft.to(device)\n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_ft.backbone.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d16ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FoodDataset(TRAIN_IMAGES_PATH, TRAIN_LABELS)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=6, shuffle=True, num_workers=8,\n",
    "    collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "params = [p for p in model_ft.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.0005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=5,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "num_epochs = 1\n",
    "model_ft.cuda()\n",
    "for epoch in range(num_epochs):\n",
    "    model_ft.train()\n",
    "\n",
    "    for i_iter, (images, targets) in enumerate(tqdm(data_loader)):\n",
    "        images = list(image.to(device) for image in images)\n",
    "#         print(targets)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "#         print(targets)\n",
    "#         break\n",
    "\n",
    "        loss_dict = model_ft(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        writer.add_scalar('Loss/train', losses, i_iter)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9bc29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
